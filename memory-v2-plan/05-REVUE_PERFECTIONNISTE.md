# Revue Perfectionniste : Architecture Memory V2

Cette revue a √©t√© effectu√©e apr√®s une analyse approfondie des fichiers `src/agent/channel.rs`, `src/agent/compactor.rs` et `src/memory/search.rs`.

## 1. Validation des Concepts

### L'Injection Silencieuse (Valid√© üü¢)
Le plan propose d'injecter les m√©moires de mani√®re invisible pour l'utilisateur et de ne pas les sauvegarder dans l'historique permanent. 
**Analyse du code :** C'est parfaitement align√© avec l'architecture actuelle. Dans `channel.rs`, la m√©thode `run_agent_turn` clone l'historique (`self.state.history.read().await.clone()`) avant de l'envoyer √† Rig. Il suffira de passer un param√®tre `injected_messages: Vec<Message>` √† `run_agent_turn` et de les ajouter au clone. Ainsi, l'LLM les verra, mais lors de la sauvegarde post-tour, ils seront ignor√©s. C'est extr√™mement √©l√©gant.

### L'√âtat d'Injection en RAM (Valid√© üü¢)
Le plan propose de stocker `ChannelInjectionState` en RAM.
**Analyse du code :** Au lieu de le mettre dans `ChannelState` (qui est un `Arc<RwLock>` partag√© avec les outils), nous pouvons le mettre directement dans la struct `Channel`. Les m√©thodes `handle_message` et `handle_message_batch` prennent `&mut self`, ce qui permet de muter cet √©tat sans aucun lock asynchrone. C'est plus performant et plus s√ªr.

## 2. Angles Morts D√©tect√©s (Les "Gotchas")

### A. Le Coalescing (Batching de messages)
**Le probl√®me :** Spacebot poss√®de un m√©canisme de `coalesce_buffer` qui regroupe les messages rapides en un seul tour LLM via `handle_message_batch`.
**La solution :** Le pre-hook ne doit pas s'ex√©cuter sur chaque petit message du buffer, mais sur le `combined_text` g√©n√©r√© dans `handle_message_batch`. Cela donnera une requ√™te de recherche beaucoup plus riche s√©mantiquement et √©vitera de spammer LanceDB.

### B. Les Messages Syst√®me (Re-triggers)
**Le probl√®me :** Quand un Worker ou une Branch termine, le syst√®me s'envoie un message synth√©tique (`source == "system"`) pour r√©veiller le Channel.
**La solution :** Il faut **d√©sactiver le pre-hook** pour les messages syst√®me. Le contexte n'a pas chang√© du point de vue de l'utilisateur, il est inutile de refaire une recherche vectorielle.

### C. Le Buffer S√©mantique et les Embeddings
**Le probl√®me :** Le plan propose de comparer la similarit√© cosinus entre les m√©moires r√©cup√©r√©es et le `semantic_buffer` (les derniers messages). Cependant, `MemorySearch::search` retourne des `Memory`, pas leurs embeddings.
**La solution :** Pour calculer la similarit√©, nous devrons appeler `self.deps.memory_search.embedding_model().embed_one(&memory.content)` √† la vol√©e pendant le pre-hook. Comme le mod√®le d'embedding tourne localement, c'est tr√®s rapide, mais il faut le faire de mani√®re asynchrone et concurrente (via `tokio::try_join!` ou `FuturesUnordered`) pour ne pas ralentir le tour de parole.

### D. L'Interaction avec le Compactor
**Le probl√®me :** Que se passe-t-il avec `injected_ids` quand le `Compactor` r√©sume l'historique ?
**La solution :** Contrairement au plan initial qui sugg√©rait de vider `injected_ids`, il est en fait pr√©f√©rable de **ne pas le vider**. Si une m√©moire a √©t√© inject√©e, elle a influenc√© la conversation. Lors de la compaction, l'essence de cette m√©moire sera captur√©e dans le r√©sum√©. Si on vide `injected_ids`, on risque de r√©injecter la m√©moire brute au prochain tour, ce qui ferait doublon avec le r√©sum√©. Nous utiliserons simplement une structure born√©e (ex: `VecDeque` de 100 √©l√©ments) pour √©viter les fuites de m√©moire.

## Conclusion de la Revue

L'architecture propos√©e est non seulement viable, mais elle s'ins√®re de mani√®re presque symbiotique dans les contraintes actuelles de Spacebot. Les modifications requises sont isol√©es et ne risquent pas de casser les fonctionnalit√©s existantes (Workers, Branches, Compactor).

**Verdict : Pr√™t pour l'impl√©mentation de la Phase 1.**
